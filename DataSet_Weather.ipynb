{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weather API \n",
    "\n",
    "\n",
    "In this NB we import the weather data, preprocess if is needed and save as a new Data Frame. \n",
    "\n",
    "\n",
    "### Historical Data \n",
    "\n",
    "For training and testing the model we use the historicla weather data related to our energy consumption data provided. \n",
    "\n",
    "For that, we'll use the API provided by [AT-Wetter](http://at-wetter.tk/index.php?men=api). We'll use this one, and not the OpenWeather API since if we want to get the historical data depth more than a week (we need a year) we'll have to use several queries. \n",
    "\n",
    "\n",
    "#### API \n",
    "\n",
    "This API don't need a Key or other autentication. It's located on the AT-Server in `http://at-wetter.tk/api/v1/.`\n",
    "The instruction to use it are in their [website](http://at-wetter.tk/index.php?men=api) \n",
    "\n",
    "#### Example \n",
    "\n",
    "To query **all the available stations** we need a call following the format: \n",
    "`/api/v1/[field]/[YYYY-MM-DD]/[day count]` \n",
    "\n",
    "A query call to `http://at-wetter.tk/api/v1/t/2014-08-01/2`  returns Temperature Data for every available station for 2014-08-01, 2 days in the past. \n",
    "\n",
    "\n",
    "\n",
    "To query just **one specific stations** we use: \n",
    "\n",
    "`/api/v1/station/[station]/[field]|[all]/[YYYY-MM-DD]/[day count]`\n",
    "\n",
    "This will return the `[field]` from the specified date `[YYYY-MM-DD]` and prints data `[day count]` days in the past for the specified stations `[station]`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calling the API\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests as rq\n",
    "import json\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* See the available stations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL =\"http://at-wetter.tk/api/v1/stations\"\n",
    "response = rq.request(\"GET\", URL)\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Calculate de day count from Building Energy Data set \n",
    "\n",
    "We cold do it manually, but in order to automated all the steps we'll calculated with a python script "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "DataFrame = pd.read_excel(\"./DataSets/Building_energy.xlsx\", header=1)\n",
    "DataFrame.head()\n",
    "\n",
    "#Calculate the Delta Time \n",
    "\n",
    "start_date = dt.datetime.strptime(DataFrame['Time'][0], \"%Y-%m-%d %H:%M:%S\")\n",
    "end_date = dt.datetime.strptime(DataFrame['Time'][len(DataFrame)-1], \"%Y-%m-%d %H:%M:%S\")\n",
    "day_count = end_date - start_date\n",
    "print(day_count.days)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the `[daycount]` field for API Query doesn't allow hours, if we have any hours of difference between the start day and the end day, we add an extra day. Then in the data frame matching we'll delethe the extra hours for the extra day. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dayCount=0 \n",
    "if day_count.seconds //3600 > 0: \n",
    "    dayCount = day_count.days + 1\n",
    "else: \n",
    "    dayCount = day_count.days\n",
    "print(dayCount)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Download the temperature data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station = '11240' #GRAZ \n",
    "field = 'all'  #Temperatuer\n",
    "days_count = str(day_count.days)\n",
    "\n",
    "URL = \"http://at-wetter.tk/api/v1/station/\"\n",
    "URL += station \n",
    "URL += \"/\" + field\n",
    "URL += \"/\" + str(end_date.year) + \"-\" + str(end_date.month) + \"-\" + str(end_date.day)\n",
    "URL += \"/\" + str(dayCount)\n",
    "response = rq.request(\"GET\", URL)\n",
    "\n",
    "print(URL)\n",
    "#print(response.text)\n",
    "type(response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#response.json(encoding=\"utf-8\")\n",
    "#print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Saving the data into a Data Frame \n",
    "\n",
    "Since the data can't be downloaded in JSON format, we first split the whole text into lineas, and then elements. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = response.text.splitlines()\n",
    "ColumnNames = [ (col.replace(\"'\",'')) for col in lines[0].split(\";\") ]\n",
    "WeatDataFrame = pd.DataFrame(columns=ColumnNames, index=range(len(lines)-2)) # -1 cause the columnames and -1 again cuase it starts from 0 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The index of the daframe starts from 0 but the first line of response.text is the ColumnName row. So we start from 0 for the DataFrame index and for idx+1 for lineas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(len(lines)-2):  \n",
    "    WeatDataFrame.iloc[idx] = [ (col.replace(\"'\",'')) for col in lines[idx+1].split(\";\") ]\n",
    "WeatDataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Changing the datum and zeit column into a newone with datetime type object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WeatDataFrame.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WeatDataFrame[\"datum\"][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime as dt \n",
    "\n",
    "dates=[] \n",
    "for idx in range(len(WeatDataFrame[\"datum\"])): \n",
    "    str_date = str(WeatDataFrame[\"datum\"][idx]) + \" \" + str(WeatDataFrame[\"zeit\"][idx])\n",
    "    dt = dt.strptime(str_date, \"%Y-%m-%d %H:%M\")\n",
    "    dates.append(dt)\n",
    "\n",
    "print(len(dates), len(WeatDataFrame.index))\n",
    "WeatDataFrame.insert(0,\"Time\",dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WeatDataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Deleting the timestamps column, zatum and zeit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WeatDataFrame.drop('datum', inplace = True, axis=1) \n",
    "WeatDataFrame.drop('zeit', inplace = True, axis=1) \n",
    "WeatDataFrame.drop('timestamp', inplace = True, axis=1) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the data frame into a csv file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'WeatDataFrame' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_218119/91200261.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mWeatDataFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./DataSets/Raw_Weather_DataSet.csv\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'WeatDataFrame' is not defined"
     ]
    }
   ],
   "source": [
    "WeatDataFrame.to_csv(\"./DataSets/Raw_Weather_DataSet.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forecast \n",
    "#### API \n",
    "\n",
    "We'll use python to request de dataset from the OpenWeather data base. The API  request call should be in this format: \n",
    "\n",
    "``` http://history.openweathermap.org/data/2.5/history/city?q={city ID},{country code}&type=hour&start={start}&end={end}&appid={API key}```\n",
    "\n",
    "#### Usage \n",
    "\n",
    "Once we introduce the day that we want to predict we request for that day's forecast. If we have it, we arrange all the necessarry inputs for that day (temp, holiday, week day,etc) and we introduce them into the model. \n",
    "\n",
    "It's gonna be an input for the user to introduce the month, day, and hour. Then we check for the necessary data for that day (if it's a monday, a holiday, etc), we make the input data array for that one and we introduce it to the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BigData",
   "language": "python",
   "name": "bigdata"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
